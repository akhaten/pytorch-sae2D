{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone --recurse-submodules https://github.com/akhaten/pytorch-sae2D.git\n",
    "!mv pytorch-sae2D/* .\n",
    "!rm -rf pytorch-sae2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \\\n",
    "    torch \\\n",
    "    pytorch-ignite \\\n",
    "    scikit-image \\\n",
    "    scikit-learn \\\n",
    "    numpy \\\n",
    "    pandas \\\n",
    "    scipy \\\n",
    "    matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# For resolve path in sae\n",
    "sys.path.append('./sae')\n",
    "# For run in children folder\n",
    "# sys.path.append('..')\n",
    "\n",
    "#from Unfolding2D import \\\n",
    "#    ModelV1 as Model, \\\n",
    "#    Trainer, \\\n",
    "#    Evaluator, \\\n",
    "#    Datas\n",
    "\n",
    "import Trainer\n",
    "import Evaluator\n",
    "# import Model\n",
    "import Datas\n",
    "import wrapper2D.defineme\n",
    "\n",
    "import torch.optim\n",
    "import torch.nn\n",
    "import torch.cuda\n",
    "import torch.utils.data\n",
    "import torch.autograd\n",
    "\n",
    "import ignite.engine\n",
    "import ignite.metrics\n",
    "import ignite.contrib.handlers\n",
    "\n",
    "import pathlib\n",
    "\n",
    "import pandas\n",
    "import numpy\n",
    "import yaml\n",
    "import sys\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_config(path: pathlib.Path) -> dict:\n",
    "    with open(path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config\n",
    "\n",
    "def save_config(config: dict, path: pathlib.Path) -> None:\n",
    "    with open(path, 'w') as outfile:\n",
    "        yaml.dump(config, outfile, default_flow_style=False)\n",
    "        \n",
    "\n",
    "    \n",
    "print(\"READ CONFIG\")\n",
    "# Read config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = pathlib.Path('./trains/train_default_params')\n",
    "config = read_config(train_folder / 'config.yml')\n",
    "\n",
    "# Make outputs paths\n",
    "output_path = pathlib.Path(config['output'].get('folder', train_folder))\n",
    "if not(output_path.exists()):\n",
    "    output_path.mkdir()\n",
    "\n",
    "models_save_path = output_path / config['output']['models_save']['path']\n",
    "if not(models_save_path.exists()):\n",
    "    models_save_path.mkdir()\n",
    "models_save_every = config['output']['models_save']['every']\n",
    "\n",
    "imgs_save_path = output_path / config['output']['imgs_save']['path']\n",
    "if not(imgs_save_path.exists()):\n",
    "    imgs_save_path.mkdir()\n",
    "\n",
    "path_imgs_train = imgs_save_path / 'train_datas'\n",
    "if not(path_imgs_train.exists()):\n",
    "    path_imgs_train.mkdir()\n",
    "\n",
    "path_imgs_eval = imgs_save_path / 'eval_datas'\n",
    "if not(path_imgs_eval.exists()):\n",
    "    path_imgs_eval.mkdir()\n",
    "\n",
    "imgs_save_every = config['output']['imgs_save']['every']\n",
    "\n",
    "# df_training_path = output_path / config['output']['metrics']['train']\n",
    "# df_validation_path = output_path / config['output']['metrics']['validation']\n",
    "loss_path = output_path / config['output']['loss']\n",
    "\n",
    "\n",
    "# Dataset params\n",
    "dataset_path = pathlib.Path(config['dataset']['path'])\n",
    "datas_device = config['dataset']['device']\n",
    "batch_size = config['dataset']['params']['batch_size']\n",
    "train_size = config['dataset']['params']['train_size']\n",
    "#datas_shuffle = config['dataset']['params']['shuffle']\n",
    "\n",
    "# Model params\n",
    "model_device = config['model']['device']\n",
    "# nb_iteration = config['model']['params']['nb_iteration']\n",
    "# nb_channel = config['model']['params']['nb_channel']\n",
    "# kernel_size = config['model']['params']['kernel_size']\n",
    "\n",
    "# Training params\n",
    "nb_epochs = config['train']['nb_epochs']\n",
    "learning_rate = config['train']['learning_rate']\n",
    "\n",
    "clip_value_using = 'gradient_clip_value' in config['train'].keys()\n",
    "if clip_value_using:\n",
    "    clip_value = config['train']['gradient_clip_value']\n",
    "\n",
    "#################################################################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make dataset / dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Dataset and Dataloaders\n",
    "dataset_full = Datas.ImageDataset(\n",
    "    dataset_path,\n",
    "    config['dataset']['params']['nb_classes'],\n",
    "    datas_device\n",
    ")\n",
    "dataset_train, dataset_validation = Datas.split_dataset(dataset_full, train_size=train_size)\n",
    "\n",
    "\n",
    "#dataset_train = dataset_train.to(datas_device, non_blocking=True)\n",
    "#dataset_validation = dataset_validation.to(datas_device, non_blocking=True)\n",
    "\n",
    "dataloader_train = torch.utils.data.DataLoader(\n",
    "    dataset_train, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "dataloader_validation= torch.utils.data.DataLoader(\n",
    "    dataset_validation, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# output_transform = \\\n",
    "#     lambda output: (output['recons'], output['inputs'])\n",
    "\n",
    "# model = Model.Unfolding(nb_channel, kernel_size, nb_iteration)\n",
    "model = wrapper2D.defineme.SegmentationAutoEncoder(\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    latent_dim=config['model']['params']['latent_dim'],\n",
    "    tau = config['model']['params']['tau']\n",
    ")\n",
    "\n",
    "model = model.to(model_device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer, Criterion ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if clip_value_using:\n",
    "    for p in model.parameters():\n",
    "        p.register_hook(\n",
    "            lambda grad: torch.clamp(grad, -clip_value, clip_value)\n",
    "        )\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    params=model.parameters(),\n",
    "    lr = learning_rate\n",
    ")\n",
    "\n",
    "criterion = wrapper2D.defineme.SAELoss2D(\n",
    "    sigma = config['train']['loss']['sigma'],\n",
    "    alpha = config['train']['loss']['alpha'],\n",
    "    beta = config['train']['loss']['beta'],\n",
    "    k = config['train']['loss']['k']\n",
    ")\n",
    "\n",
    "lr_scheduler = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Ignite Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step = Trainer.create_train_step(\n",
    "    model, model_device, datas_device, optimizer, criterion, lr_scheduler\n",
    ")\n",
    "\n",
    "trainer = ignite.engine.Engine(train_step)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event for loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = []\n",
    "\n",
    "#### Event handler\n",
    "\n",
    "trainer.add_event_handler(\n",
    "    ignite.engine.Events.EPOCH_COMPLETED,\n",
    "    # Callback\n",
    "    Trainer.update_loss_history,\n",
    "    # Parameters of callback\n",
    "    loss_history\n",
    ")\n",
    "\n",
    "trainer.add_event_handler(\n",
    "    ignite.engine.Events.EPOCH_COMPLETED,\n",
    "    # Callback\n",
    "    Trainer.save_loss_history,\n",
    "    # Parameters of callback\n",
    "    loss_history, \n",
    "    loss_path\n",
    ")\n",
    "\n",
    "trainer.add_event_handler(\n",
    "    ignite.engine.Events.EPOCH_COMPLETED,\n",
    "    # Callback\n",
    "    Trainer.clean_saeloss,\n",
    "    # Parameters of callback\n",
    "    criterion, \n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Events for validation datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.add_event_handler(\n",
    "    ignite.engine.Events.EPOCH_COMPLETED(every=imgs_save_every),\n",
    "    # Callback\n",
    "    Evaluator.evaluate_dataloader,\n",
    "    # Parameters of callback\n",
    "    model,\n",
    "    model_device,\n",
    "    datas_device,\n",
    "    dataloader_train,\n",
    "    path_imgs_train\n",
    ")\n",
    "\n",
    "trainer.add_event_handler(\n",
    "    ignite.engine.Events.COMPLETED,\n",
    "    # Callback\n",
    "    Evaluator.evaluate_dataloader,\n",
    "    # Parameters of callback\n",
    "    model,\n",
    "    model_device,\n",
    "    datas_device,\n",
    "    dataloader_train,\n",
    "    path_imgs_train\n",
    ")\n",
    "\n",
    "trainer.add_event_handler(\n",
    "    ignite.engine.Events.EPOCH_COMPLETED(every=imgs_save_every),\n",
    "    # Callback\n",
    "    Evaluator.evaluate_dataloader,\n",
    "    # Parameters of callback\n",
    "    model,\n",
    "    model_device,\n",
    "    datas_device,\n",
    "    dataloader_validation,\n",
    "    path_imgs_eval\n",
    ")\n",
    "\n",
    "trainer.add_event_handler(\n",
    "    ignite.engine.Events.COMPLETED,\n",
    "    # Callback\n",
    "    Evaluator.evaluate_dataloader,\n",
    "    # Parameters of callback\n",
    "    model,\n",
    "    model_device,\n",
    "    datas_device,\n",
    "    dataloader_validation,\n",
    "    path_imgs_eval\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Others event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.add_event_handler(\n",
    "    # ignite.engine.Events.COMPLETED,\n",
    "    ignite.engine.Events.EPOCH_COMPLETED(every=models_save_every),\n",
    "    # Callback\n",
    "    Trainer.save_model,\n",
    "    # Parameters of callback\n",
    "    model,\n",
    "    models_save_path\n",
    ")\n",
    "\n",
    "trainer.add_event_handler(\n",
    "    # ignite.engine.Events.COMPLETED,\n",
    "    ignite.engine.Events.COMPLETED,\n",
    "    # Callback\n",
    "    Trainer.save_model,\n",
    "    # Parameters of callback\n",
    "    model,\n",
    "    models_save_path\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make evaluator\n",
    "# evaluate_function = Evaluator.create_evaluate_function(model, model_device, datas_device)\n",
    "# evaluator = ignite.engine.Engine(evaluate_function)\n",
    "\n",
    "#### MAE METRICS\n",
    "\n",
    "# mae = ignite.metrics.MeanAbsoluteError(output_transform)\n",
    "# avg_mae = ignite.metrics.RunningAverage(src=mae, epoch_bound=False)\n",
    "\n",
    "# mae.attach(engine=evaluator, name='mae')\n",
    "# avg_mae.attach(engine=evaluator, name='avg_mae')\n",
    "\n",
    "#### MSE METRICS\n",
    "\n",
    "# mse = ignite.metrics.MeanSquaredError(output_transform)\n",
    "# avg_mse = ignite.metrics.RunningAverage(src=mse, epoch_bound=False)\n",
    "\n",
    "# mse.attach(engine=evaluator, name='mse')\n",
    "# avg_mse.attach(engine=evaluator, name='avg_mse')\n",
    "\n",
    "#### History\n",
    "\n",
    "# validation_history = {\n",
    "#     'mae' : [],\n",
    "#     'avg_mae' : [],\n",
    "#     'mse' : [],\n",
    "#     'avg_mse' : []\n",
    "# }\n",
    "\n",
    "# training_history = {\n",
    "#     'mae' : [],\n",
    "#     'avg_mae' : [],\n",
    "#     'mse' : [],\n",
    "#     'avg_mse' : [],\n",
    "# }\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#trainer.add_event_handler(\n",
    "#    ignite.engine.Events.EPOCH_COMPLETED,\n",
    "#    # Callback\n",
    "#    Trainer.print_logs\n",
    "#)\n",
    "\n",
    "## Evaluation on datas using for training\n",
    "# trainer.add_event_handler(\n",
    "#     ignite.engine.Events.EPOCH_COMPLETED,\n",
    "#     # Callback\n",
    "#     Evaluator.update_history_metrics,\n",
    "#     # Parameters of callback\n",
    "#     evaluator, \n",
    "#     dataloader_train, \n",
    "#     training_history\n",
    "# )\n",
    "\n",
    "## Evaluation on datas using for validation\n",
    "# trainer.add_event_handler(\n",
    "#     ignite.engine.Events.EPOCH_COMPLETED,\n",
    "#     # Callback\n",
    "#     Evaluator.update_history_metrics,\n",
    "#     # Parameters of callback\n",
    "#     evaluator, \n",
    "#     dataloader_validation, \n",
    "#     validation_history\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = trainer.run(dataloader_train, max_epochs=nb_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save metrics\n",
    "\n",
    "# df_training = pandas.DataFrame(training_history)\n",
    "# df_validation = pandas.DataFrame(validation_history)\n",
    "\n",
    "# df_training.to_pickle(df_training_path)\n",
    "# df_validation.to_pickle(df_validation_path)\n",
    "\n",
    "\n",
    "# Save loss\n",
    "loss = numpy.array(loss_history)\n",
    "numpy.save(loss_path, loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
