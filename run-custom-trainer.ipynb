{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone --recurse-submodules https://github.com/akhaten/pytorch-sae2D.git\n",
    "!mv pytorch-sae2D/* .\n",
    "!rm -rf pytorch-sae2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \\\n",
    "    torch \\\n",
    "    pytorch-ignite \\\n",
    "    scikit-image \\\n",
    "    scikit-learn \\\n",
    "    numpy \\\n",
    "    pandas \\\n",
    "    scipy \\\n",
    "    matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./sae')\n",
    "\n",
    "#from Unfolding2D import \\\n",
    "#    ModelV1 as Model, \\\n",
    "#    Trainer, \\\n",
    "#    Evaluator, \\\n",
    "#    Datas\n",
    "\n",
    "import CustomTrainer\n",
    "import Evaluator\n",
    "# import wrapper2D.defineme\n",
    "import Datas\n",
    "\n",
    "import torch.optim\n",
    "import torch.nn\n",
    "import torch.cuda\n",
    "import torch.utils.data\n",
    "import torch.autograd\n",
    "\n",
    "import ignite.engine\n",
    "import ignite.metrics\n",
    "import ignite.contrib.handlers\n",
    "\n",
    "import pathlib\n",
    "\n",
    "import pandas\n",
    "import numpy\n",
    "import yaml\n",
    "import sys\n",
    "\n",
    "import wrapper2D.models\n",
    "import wrapper2D.defineme\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_config(path: pathlib.Path) -> dict:\n",
    "    with open(path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config\n",
    "\n",
    "def save_config(config: dict, path: pathlib.Path) -> None:\n",
    "    with open(path, 'w') as outfile:\n",
    "        yaml.dump(config, outfile, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read config\n",
    "train_folder = pathlib.Path('./trains/train_default_params')\n",
    "config = read_config(train_folder / 'config.yml')\n",
    "\n",
    "# Make outputs paths\n",
    "output_path = pathlib.Path(config['output'].get('folder', train_folder))\n",
    "if not(output_path.exists()):\n",
    "    output_path.mkdir()\n",
    "\n",
    "models_save_path = output_path / config['output']['models_save']['path']\n",
    "if not(models_save_path.exists()):\n",
    "    models_save_path.mkdir()\n",
    "models_save_every = config['output']['models_save']['every']\n",
    "\n",
    "imgs_save_path = output_path / config['output']['imgs_save']['path']\n",
    "if not(imgs_save_path.exists()):\n",
    "    imgs_save_path.mkdir()\n",
    "\n",
    "path_imgs_train = imgs_save_path / 'train_datas'\n",
    "if not(path_imgs_train.exists()):\n",
    "    path_imgs_train.mkdir()\n",
    "\n",
    "path_imgs_eval = imgs_save_path / 'eval_datas'\n",
    "if not(path_imgs_eval.exists()):\n",
    "    path_imgs_eval.mkdir()\n",
    "\n",
    "imgs_save_every = config['output']['imgs_save']['every']\n",
    "\n",
    "# df_training_path = output_path / config['output']['metrics']['train']\n",
    "# df_validation_path = output_path / config['output']['metrics']['validation']\n",
    "loss_path = output_path / config['output']['loss']\n",
    "\n",
    "\n",
    "# Dataset params\n",
    "dataset_path = pathlib.Path(config['dataset']['path'])\n",
    "datas_device = config['dataset']['device']\n",
    "batch_size = config['dataset']['params']['batch_size']\n",
    "train_size = config['dataset']['params']['train_size']\n",
    "#datas_shuffle = config['dataset']['params']['shuffle']\n",
    "\n",
    "# Model params\n",
    "model_device = config['model']['device']\n",
    "# nb_iteration = config['model']['params']['nb_iteration']\n",
    "# nb_channel = config['model']['params']['nb_channel']\n",
    "# kernel_size = config['model']['params']['kernel_size']\n",
    "\n",
    "# Training params\n",
    "nb_epochs = config['train']['nb_epochs']\n",
    "learning_rate = config['train']['learning_rate']\n",
    "\n",
    "clip_value_using = 'gradient_clip_value' in config['train'].keys()\n",
    "if clip_value_using:\n",
    "    clip_value = config['train']['gradient_clip_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Dataset and Dataloaders\n",
    "dataset_full = Datas.ImageDataset(\n",
    "    dataset_path,\n",
    "    datas_device\n",
    ")\n",
    "dataset_train, dataset_validation = Datas.split_dataset(dataset_full, train_size=train_size)\n",
    "    dataloader_train = torch.utils.data.DataLoader(\n",
    "    dataset_train, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "dataloader_validation= torch.utils.data.DataLoader(\n",
    "    dataset_validation, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Make Trainer\n",
    "\n",
    "# output_transform = \\\n",
    "#     lambda output: (output['recons'], output['inputs'])\n",
    "\n",
    "# model = Model.Unfolding(nb_channel, kernel_size, nb_iteration)\n",
    "model = wrapper2D.defineme.SegmentationAutoEncoder(\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    latent_dim=config['model']['params']['latent_dim'],\n",
    "    tau = config['model']['params']['tau']\n",
    ")\n",
    "model = model.to(model_device)\n",
    "\n",
    "if clip_value_using:\n",
    "    for p in model.parameters():\n",
    "        p.register_hook(\n",
    "            lambda grad: torch.clamp(grad, -clip_value, clip_value)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "    params=model.parameters(),\n",
    "    lr = learning_rate\n",
    ")\n",
    "\n",
    "# criterion = ignite.metrics.MeanAbsoluteError(output_transform)\n",
    "#criterion = ignite.metrics.MeanAbsoluteError(output_transform)\n",
    "# criterion = torch.nn.MSELoss()\n",
    "criterion = wrapper2D.defineme.SAELoss2D(\n",
    "    sigma = config['train']['loss']['sigma'],\n",
    "    alpha = config['train']['loss']['alpha'],\n",
    "    beta = config['train']['loss']['beta'],\n",
    "    k = config['train']['loss']['k']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #model = model.to(model_device)\n",
    "train_step = CustomTrainer.create_train_step(\n",
    "    model, model_device, datas_device, optimizer, criterion\n",
    ")\n",
    "\n",
    "trainer = CustomTrainer.CustomEngine(train_step)\n",
    "trainer.add_event_handler(\n",
    "    ignite.engine.Events.ITERATION_COMPLETED,\n",
    "    CustomTrainer.update_epoch_loss\n",
    ")\n",
    "trainer.add_event_handler(\n",
    "    ignite.engine.Events.EPOCH_COMPLETED,\n",
    "    CustomTrainer.compute_epoch_loss\n",
    ")\n",
    "trainer.add_event_handler(\n",
    "    ignite.engine.Events.EPOCH_COMPLETED,\n",
    "    CustomTrainer.save_epoch_loss,\n",
    "    loss_path\n",
    ")\n",
    "trainer.add_event_handler(\n",
    "    ignite.engine.Events.EPOCH_COMPLETED,\n",
    "    # Callback\n",
    "    CustomTrainer.clean_saeloss,\n",
    "    # Parameters of callback\n",
    "    criterion, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.add_event_handler(\n",
    "    # ignite.engine.Events.COMPLETED,\n",
    "    ignite.engine.Events.EPOCH_COMPLETED(every=models_save_every) \n",
    "    | ignite.engine.Events.COMPLETED,\n",
    "    # Callback\n",
    "    CustomTrainer.save_model,\n",
    "    # Parameters of callback\n",
    "    model,\n",
    "    models_save_path\n",
    ")\n",
    "\n",
    "trainer.add_event_handler(\n",
    "    ignite.engine.Events.EPOCH_COMPLETED(every=imgs_save_every)\n",
    "    | ignite.engine.Events.COMPLETED,\n",
    "    # Callback\n",
    "    Evaluator.evaluate_dataloader,\n",
    "    # Parameters of callback\n",
    "    model,\n",
    "    model_device,\n",
    "    datas_device,\n",
    "    dataloader_train,\n",
    "    path_imgs_train\n",
    ")\n",
    "\n",
    "\n",
    "trainer.add_event_handler(\n",
    "    ignite.engine.Events.EPOCH_COMPLETED(every=imgs_save_every)\n",
    "    | ignite.engine.Events.COMPLETED,\n",
    "    # Callback\n",
    "    Evaluator.evaluate_dataloader,\n",
    "    # Parameters of callback\n",
    "    model,\n",
    "    model_device,\n",
    "    datas_device,\n",
    "    dataloader_validation,\n",
    "    path_imgs_eval\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = trainer.run(dataloader_train, max_epochs=nb_epochs)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
